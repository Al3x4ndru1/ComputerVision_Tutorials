{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cascade Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ca sa pot sa incep am nevie de 2 seturi de imagini, un set pozitiv(cu fete) si un set negativ(care nu are fete)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/faces.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a personal detector we must download images from internet and send the images a machine learning alghorithm called AdaBoost Training. This alghorithm will select the features of the images. Each square image shows what exactly they are, which are little white and black square with different shapes. The idea is to apply each of this square in the image to each sub-window of the image. (Will g from the left to right) ( I can consider the black points as the 1, when is is found, and the withe as 0, when it is not found)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/FeatureSelction.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basics equasion: Sum of white pixels - sum of black pixels.\n",
    "\n",
    "<br>\n",
    "\n",
    "For example: \n",
    "\n",
    "<br>\n",
    "\n",
    "if we have 24 pixels white pixels and 24 black pixels that means we have more than 160.000 combination to apply to that image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ideea of putting the features into the image is called sliding window. After the small squares will finish filling the image we will apply the equasion. At the end we will have a matrix of numbers, similar to:\n",
    "\n",
    "<br>\n",
    "\n",
    "2 3 5 6\n",
    "<br>\n",
    "8 9 2 1\n",
    "<br>\n",
    "\n",
    "The name of the classifier is called cascade, because we are going from top to bottom of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/Classifiers.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example we have the red spot and that can be the algorithm to find the eyes the black pixels is on the eye."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the alghorithm is trained we have another stage called _Cascade_, which is the process to clasify the image( to detect the object/face)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/Cascade.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image is getting and each _C_ represents a classifiers( are those features, squares). If feature 1 does not exist will terminate the and return _No Detection_. If the feature1 exist then will go to feature2. If a single feature does not exist the alghorithm will retuen _No Detection_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Loading the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: QT_DEVICE_PIXEL_RATIO is deprecated. Instead use:\n",
      "   QT_AUTO_SCREEN_SCALE_FACTOR to enable platform plugin controlled per-screen factors.\n",
      "   QT_SCREEN_SCALE_FACTORS to set per-screen DPI.\n",
      "   QT_SCALE_FACTOR to set the application global scale factor.\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "frame = cv.imread('./imgs/people.jpg') # read the image\n",
    "frame.shape # see the parameters of the image\n",
    "\n",
    "cv.imshow('test',frame) # show the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Detecting faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/al3x4ndru1/ComputerVision/Face_detection/Face_detection.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/al3x4ndru1/ComputerVision/Face_detection/Face_detection.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m face_detector \u001b[39m=\u001b[39m cv\u001b[39m.\u001b[39mCascadeClassifier(\u001b[39m'\u001b[39m\u001b[39m./haarcascades/haarcascade_frontalface_default.xml\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m# create object for CascadeClassifier \u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/al3x4ndru1/ComputerVision/Face_detection/Face_detection.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                                                                                            \u001b[39m# for recognising frontal faces\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/al3x4ndru1/ComputerVision/Face_detection/Face_detection.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m frame \u001b[39m=\u001b[39m cv\u001b[39m.\u001b[39mimread(\u001b[39m'\u001b[39m\u001b[39m./imgs/people.jpg\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m# read the image\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv' is not defined"
     ]
    }
   ],
   "source": [
    "face_detector = cv.CascadeClassifier('./haarcascades/haarcascade_frontalface_default.xml') # create object for CascadeClassifier \n",
    "                                                                                           # for recognising frontal faces\n",
    "\n",
    "frame = cv.imread('./imgs/people.jpg') # read the image\n",
    "frame.shape # see the parameters of the image\n",
    "\n",
    "detection = face_detector.detectMultiScale(frame) # create an object for the processed image\n",
    "print(detection)\n",
    "len(detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250 212 254 254\n",
      "539 281 291 291\n",
      "1354 497 62 62\n",
      "784 544 304 304\n",
      "996 550 290 290\n",
      "251 608 324 324\n"
     ]
    }
   ],
   "source": [
    "for(x,y,w,h) in detection: #create a for that will traverse the detection object\n",
    "    print(x,y,w,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'detection' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/al3x4ndru1/ComputerVision/Face_detection/Face_detection.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/al3x4ndru1/ComputerVision/Face_detection/Face_detection.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m(x,y,w,h) \u001b[39min\u001b[39;00m detection: \u001b[39m#create a for that will traverse the detection object\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/al3x4ndru1/ComputerVision/Face_detection/Face_detection.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m#             the image(original)      where the rectangle starts       where the rectangle terminates     color in BGR         tichness   \u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/al3x4ndru1/ComputerVision/Face_detection/Face_detection.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     cv\u001b[39m.\u001b[39mrectangle(       frame,                          (x,y),                      (x,y),                          (\u001b[39m0\u001b[39m,\u001b[39m255\u001b[39m,\u001b[39m0\u001b[39m),          \u001b[39m2\u001b[39m) \u001b[39m# drow the rectangle\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/al3x4ndru1/ComputerVision/Face_detection/Face_detection.ipynb#X34sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m cv\u001b[39m.\u001b[39mimshow(\u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m,frame)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'detection' is not defined"
     ]
    }
   ],
   "source": [
    "for(x,y,w,h) in detection: #create a for that will traverse the detection object\n",
    "    #             the image(original)      where the rectangle starts       where the rectangle terminates     color in BGR         tichness   \n",
    "    cv.rectangle(       frame,                          (x,y),                      (x,y),                          (0,255,0),          2) # drow the rectangle\n",
    "\n",
    "cv.imshow('a',frame)\n",
    "# for a dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for(x,y,w,h) in detection: #create a for that will traverse the detection object\n",
    "    #             the image(original)      where the rectangle starts       where the rectangle terminates     color in BGR         tichness   \n",
    "    cv.rectangle(       frame,                          (x+w,y),                      (x,y),                          (0,255,0),          2) # drow the rectangle\n",
    "\n",
    "cv.imshow('a',frame)\n",
    "# for a line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'detection' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/al3x4ndru1/ComputerVision/Face_detection/Face_detection.ipynb Cell 21\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/al3x4ndru1/ComputerVision/Face_detection/Face_detection.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m(x,y,w,h) \u001b[39min\u001b[39;00m detection: \u001b[39m#create a for that will traverse the detection object\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/al3x4ndru1/ComputerVision/Face_detection/Face_detection.ipynb#X36sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m#             the image(original)      where the rectangle starts       where the rectangle terminates     color in BGR         tichness   \u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/al3x4ndru1/ComputerVision/Face_detection/Face_detection.ipynb#X36sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     cv\u001b[39m.\u001b[39mrectangle(       frame,                          (x\u001b[39m+\u001b[39mw,y\u001b[39m+\u001b[39mh),                      (x,y),                          (\u001b[39m0\u001b[39m,\u001b[39m255\u001b[39m,\u001b[39m0\u001b[39m),          \u001b[39m2\u001b[39m) \u001b[39m# drow the rectangle\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/al3x4ndru1/ComputerVision/Face_detection/Face_detection.ipynb#X36sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m cv\u001b[39m.\u001b[39mimshow(\u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m,frame)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'detection' is not defined"
     ]
    }
   ],
   "source": [
    "for(x,y,w,h) in detection: #create a for that will traverse the detection object\n",
    "    #             the image(original)      where the rectangle starts       where the rectangle terminates     color in BGR         tichness   \n",
    "    cv.rectangle(       frame,                          (x+w,y+h),                      (x,y),                          (0,255,0),          2) # drow the rectangle\n",
    "\n",
    "cv.imshow('a',frame)\n",
    "# for a rectangle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Haarcascade parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> ScaleFactor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale parameter is used to automaticallyscale the image. For instance in the previous example we had an error, a face was detected where no face was. The default scale is 1.1, we are not allowed to scale less than 1. If we will put 1.01 more faces(errors will appear).  If we will put it more, for instance 1.5 some faces will not be detected.\n",
    "<br>\n",
    "The scale must be put it in concordance with the image. If we have small images the scale will be small. If we have large images the scale will be large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The errors are called false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> minNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is kind of the opposite of ScaleFactor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to choose if we want to have more quanti or more detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> minSize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default value is 30x30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimum value of the box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> maxSize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum value of the box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eye detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an object for the prebuild classifier for eyes.\n",
    "\n",
    "<br>\n",
    "\n",
    "Make the same for loop for drowing the rectangles, but now for eyes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_detect = eye_detection.detectMultiScale(frame)\n",
    "\n",
    "for (x, y, w, h) in eye_detect:\n",
    "    cv.rectangle(frame,(x,y),(x+w,y+h),(0,0,255),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also put the scale factor, as well, but can give as true positive results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
